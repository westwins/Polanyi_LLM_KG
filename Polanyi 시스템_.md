

# **Polanyi 시스템: LLM과 지식 그래프를 융합한 인간 수준의 이해를 향한 뉴로심볼릭 접근법 분석**

## **1\. 서론: 인간과 같은 이해를 향한 AI의 근본적 도전**

인공지능(AI) 분야는 오랫동안 인간의 복잡한 추론 및 이해 능력을 모방하는 시스템 개발이라는 원대한 목표를 추구해왔습니다. 이 과정에서 두 가지 주요 패러다임, 즉 생성형 AI와 지식 기반 AI가 부상했지만, 각각은 명확한 한계를 지니고 있습니다. 본 보고서는 "Grounded World Models를 위한 뉴로심볼릭 그래프 강화(Neurosymbolic graph enrichment for Grounded World Models)"라는 제목의 논문 1을 심층 분석하여, 이 두 패러다임의 간극을 메우고 진정한 의미의 '접지된(grounded)' 이해에 도달하려는 새로운 뉴로심볼릭 접근법을 탐구합니다. 특히, 저자들이 공개한

StenDoipanni/XKG 깃허브 저장소 2의 구현 세부 사항을 참조하여, 이론적 제안이 실제 시스템에서 어떻게 구현되고 작동하는지를 면밀히 검토합니다.

### **1.1 신호와 기호 사이의 심연**

AI의 발전사를 관통하는 핵심적인 이분법은 신호 처리와 기호 처리 사이의 대립입니다. 논문은 이 지점을 명확히 짚으며 논의를 시작합니다. 대규모 언어 모델(LLM)을 포함한 생성형 AI는 본질적으로 "신호 처리 기계(signal processing machines)"로 정의됩니다.1 이들은 방대한 데이터로부터 입력 신호의 통계적 패턴을 학습하고, 추론 시점에 그럴듯한 기호적 출력(텍스트, 이미지 등)을 생성합니다. 이들의 강점은 유연성과 방대한 잠재 지식에 있지만, 생성된 정보가 현실 세계와 어떻게 연결되는지에 대한 내재적 이해, 즉 '접지'가 부족합니다.

반면, 지식 기반 AI는 "논리 기계(logical machines)"로 작동합니다.1 이 시스템들은 세상에 대한 지식을 명시적인 기호(예: 온톨로지, 규칙)로 표현하고, 모델 이론적 해석(model-theoretical interpretations)에 기반하여 논리적으로 타당한 추론을 수행합니다. 이들의 강점은 정확성과 설명 가능성이지만, 미리 정의된 지식의 범위를 벗어나는 예외적이거나 암시적인 상황에 대처하기 어렵고, 지식 기반 구축에 막대한 비용과 노력이 소요되는 경직성을 가집니다.

이 두 패러다임 사이의 근본적인 차이는 AI가 진정한 이해에 도달하는 것을 가로막는 거대한 심연을 만듭니다. 이 심연의 본질을 이해하기 위해, 논문이 제안하는 시스템의 이름인 '폴라니(Polanyi)'에 주목할 필요가 있습니다. 이는 "우리는 말할 수 있는 것보다 더 많이 알 수 있다"는 명제로 유명한 철학자 마이클 폴라니의 '암묵적 지식(tacit knowledge)' 개념에서 유래했습니다.1 LLM은 인터넷의 방대한 텍스트, 즉 인간이 '말한' 명시적 지식을 학습합니다. 지식 그래프(KG) 역시 전문가가 명시적으로 '정의한' 사실과 규칙으로 구성됩니다. 그렇다면 이 두 접근법이 모두 놓치고 있는 것은 바로 인간의 상호작용과 이해의 기반을 이루는, 말로 표현되지 않은 방대한 양의 암묵적 지식입니다. 여기에는 사회적 규범, 문화적 배경, 신체적 직관, 상식 등이 포함됩니다. 따라서 이 논문이 해결하고자 하는 문제는 단순히 두 기술을 결합하는 기술적 과제를 넘어, AI의 다음 단계로 나아가기 위해 필수적인 '암묵적 지식'을 어떻게 형식화하고 추출할 것인가에 대한 근본적인 지식 표현의 도전이라고 재정의할 수 있습니다.

### **1.2 프레임 문제: AI의 맥락과 관련성 투쟁**

논문은 자신들의 연구가 AI의 고전적인 난제인 "프레임 문제(Frame problem)"를 다루고 있음을 명시적으로 밝힙니다.1 프레임 문제는 AI 시스템이 특정 상황에서 어떤 정보가 관련 있고 어떤 정보는 무시해도 되는지를 판단하여, "선택의 조합적 공간을 대폭 줄이는(massively reducing the combinatorial space of choices)" 능력의 부재를 지적합니다.1 예를 들어, 방에 들어갈 때 벽의 색깔이 바뀌지 않았다는 사실까지 일일이 확인할 필요가 없는 것처럼, 인간은 무의식적으로 관련 없는 가능성을 배제합니다. AI에게 이러한 능력을 부여하는 것은 매우 어려운 과제입니다.

이러한 관점에서 볼 때, 논문이 제안하는 '폴라니' 파이프라인은 단순한 지식 추가 도구가 아니라, 일종의 '관련성 엔진(relevance engine)'으로 기능합니다. 시스템은 11가지의 구체적인 휴리스틱(예: 전제, 대화 함의, 사실적 영향 등)을 사용하여 기본 지식 그래프를 확장합니다.1 이 휴리스틱들은 무작위로 선택된 것이 아니라, 인간이 관련성을 판단하는 다양한 방식을 모방하도록 설계되었습니다. 예를 들어, '대화 함의(Conversational Implicatures)' 휴리스틱은 대화에서 명시적으로 말해지지는 않았지만 관련성 있는 의미를 추론하는 데 초점을 맞춥니다. '암시된 미래 사건(Implied Future Events)' 휴리스틱은 현재 상황에서 고려해야 할 관련성 있는 다음 단계를 예측합니다.

결국 이 파이프라인은 '더 많은 지식'을 추가하는 것이 아니라, LLM이 가진 방대하고 미분화된 잠재 공간을 특정하고 맥락적으로 관련된 의미의 축으로 집중시키는 역할을 합니다. 각 휴리스틱은 특정 유형의 관련성을 포착하는 렌즈처럼 작동하여, 무한에 가까운 가능성의 공간을 인간과 유사한 방식으로 가지치기합니다. 이는 프레임 문제에 대한 해결책이 단일한 거대 알고리즘이 아니라, 인간의 다양한 추론 방식을 모방하는 전문화된 '관련성 휴리스틱'의 집합을 통해 달성될 수 있음을 시사합니다. 논문의 모듈식 접근 방식은 이러한 철학적 해법을 실용적으로 구현한 결과물이라 할 수 있습니다.

### **1.3 접지된 세계 모델(GWMs): 궁극적인 목표**

이 연구의 궁극적인 목표는 "인간에 의해 경험되거나 구성된 세계의 모델(models of the world as experienced or constructed by humans)"로서, "물리적, 신경인지적, 사회적, 문화적 차원을 포괄하는" 접지된 세계 모델(Grounded World Models, GWMs)의 구축입니다.1 이는 단순히 더 나은 지식 그래프나 더 똑똑한 LLM을 만드는 것을 넘어, 시스템의 내부 표현이 인간 경험의 다차원적 현실과 의미 있는 대응 관계를 갖도록 하는 것을 목표로 합니다.

이러한 목표 아래에서, 파이프라인의 최종 산출물인 '확장된 지식 그래프(Extended Knowledge Graph, XKG)'는 단순한 데이터 구조 이상의 의미를 가집니다. XKG는 기본 그래프(Base Graph)와 11개 휴리스틱으로부터 생성된 모든 트리플을 병합한 결과물입니다.1 여기서 기본 그래프는 이미지나 텍스트에 명시적으로 드러난, 관찰 가능한 세계를 나타냅니다. 반면, 11개의 휴리스틱 기반 확장은 GWM의 암묵적 층위를 표현합니다. 예를 들어, '도덕적 가치 기반 강제(Moral Value-driven Coercion)'는 사회적 규범을, '이미지 스키마(Image Schemas)'는 물리적 직관을, '인과 관계(Causal Relations)'는 인과적 믿음을 형식화합니다.

따라서 XKG는 특정 맥락에 대한 GWM의 정적이고 형식적인 '스냅샷'이라고 볼 수 있습니다. 이 연구의 진정한 산출물은 개별 XKG 자체가 아니라, 그것을 생성하는 *프로세스*입니다. 이 프로세스는 어떤 새로운 맥락(이미지, 뉴스 기사 등)이 주어지더라도 그에 대한 GWM 스냅샷을 생성할 수 있는 복제 가능한 방법론을 제공하며, 이는 접근법의 동적인 확장성을 보장합니다.

## **2\. 폴라니 프레임워크: 지식 강화를 위한 뉴로심볼릭 접근법**

폴라니 프레임워크는 LLM의 생성 능력과 지식 그래프의 구조적 강점을 결합하여 인간 수준의 이해에 더 가까이 다가가려는 시도입니다. 이 섹션에서는 프레임워크의 핵심 철학과 아키텍처를 분석하고, 기존 AI 연구 지형 내에서 그 독창적인 위치를 조명합니다.

### **2.1 핵심 철학: "잠재적 반응자"로서의 LLM**

이 연구의 가장 혁신적인 측면 중 하나는 LLM을 사용하는 방식에 대한 관점의 전환입니다. 대부분의 연구는 LLM을 질문에 답하고, 텍스트를 요약하며, 코드를 생성하는 등 명시적인 지식의 원천, 즉 "전문가 시스템(expert systems)"으로 취급합니다. 그러나 이 논문은 LLM을 "암묵적인 맥락적 지식을 추출하기 위한 반응 엔진(reactive engines to extract implicit contextual knowledge)"으로 재정의합니다.1 즉, LLM은 "적절한 휴리스틱으로 활성화될 때(activated with appropriate heuristics)" 그 "반응 능력(reactive power)"을 발휘하는 매개체로 간주됩니다.1

이러한 접근법은 LLM을 일종의 시뮬레이션된 '문화적 수프(cultural soup)' 또는 '상식 물리 엔진(commonsense physics engine)'으로 활용하는 것과 같습니다. 시스템이 LLM에게 던지는 프롬프트는 "무엇이 사실인가?"가 아니라, "이 상황에서 무엇이 암시/전제/느껴질 것인가?"에 가깝습니다. 이는 LLM의 잠재 공간(latent space)을 탐색하는 방식에 대한 깊은 이해를 바탕으로 합니다. LLM의 잠재 공간은 개념들이 복잡하게 얽혀 있는 고차원의 다양체(manifold)입니다. 일반적인 프롬프트가 이 공간의 넓고 분산된 영역을 활성화시킨다면, 폴라니 시스템의 휴리스틱 기반 프롬프트는 마치 '소리굽쇠(tuning fork)'처럼 작동합니다.

각각의 휴리스틱별 프롬프트는 잠재 공간 내에서 매우 특정한 '주파수' 또는 차원, 즉 도덕적 가치, 인과성, 전제 등과 관련된 차원이 공명하도록 설계되었습니다. 그러면 LLM은 그 활성화된 차원을 따라 개념들을 반영하는 텍스트(이후 트리플로 형식화됨)를 생성하며 '반응'합니다. 이는 '지식 증강 생성(Knowledge Augmented Generation, KAG)'에 대한 더 정교하고 강력한 메커니즘을 제시합니다. KAG는 단순히 사실을 검색하여 프롬프트에 추가하는 것을 넘어, 사전 학습된 세계 모델의 특정 차원을 표적화하여 활성화시키는 과정으로 이해될 수 있습니다.

### **2.2 하이브리드 아키텍처 (카우츠 분류법 & 그래프 RAG)**

논문은 제안된 파이프라인의 위치를 학문적으로 명확히 하기 위해 카우츠(Kautz)의 뉴로심볼릭 시스템 분류법을 인용합니다. 이 시스템은 "유형 2(Symbolic \[Neuro\] (Nested))"와 "유형 3(Neuro; Symbolic (Cooperative))" 아키텍처의 특성을 모두 가집니다.1

* **유형 2 (중첩형)**: 기호적 추론 시스템(KG와 그 기반인 OWL2 논리)이 주 시스템으로 기능하고, 신경망(LLM)이 내부적인 결정(어떤 트리플을 추가할지)을 내리는 데 사용됩니다.  
* **유형 3 (협력형)**: 신경망(예: 개체 연결)과 기호적 추론기(의미론적 그래프 구축)가 상호 보완적인 작업을 수행하며 입출력을 통해 상호작용합니다.

또한, 논문은 자신들의 접근법이 최근 주목받는 그래프 검색 증강 생성(Graph RAG)과 어떻게 다른지를 명확히 구분합니다. 표준적인 그래프 RAG는 KG에서 명시적인 사실을 검색하여 LLM의 프롬프트를 보강하는 방식입니다. 반면, 폴라니 파이프라인은 정반대의 작업을 수행합니다. 즉, LLM을 사용하여 KG를 보강할 *새로운 사실(암묵적 지식)을 생성*합니다. 이는 LLM을 "압축된 정보 검색 도구(tools for compressed information retrieval)"가 아닌 "잠재적 반응자(latent reactors)"로 사용하는 핵심 철학과 일맥상통합니다.1

이러한 아키텍처는 단방향 파이프라인을 넘어, 뉴로심볼릭 정제의 "선순환 구조(virtuous cycle)"를 내포하고 있습니다. 파이프라인은 LLM(이미지 설명)에서 시작하여 기호적 표현(기본 그래프)으로, 다시 LLM(강화)으로, 그리고 최종적으로 더 복잡한 기호적 표현(XKG)으로 이어집니다.1 이론적으로, 이렇게 생성된 더 정확한 GWM 스냅샷인 XKG는

*새로운* LLM을 미세 조정(fine-tuning)하는 데 사용될 수 있습니다. 이 새로운 LLM은 더 풍부하고 구조화된 지식에 '접지'될 것이며, 다시 파이프라인에 투입되었을 때 더 나은 초기 설명과 강화 결과를 생성할 것입니다. 이는 신경망과 기호적 구성 요소가 함께 진화하며 서로를 향상시키는 자기 개선 루프의 청사진을 제시합니다. 이것은 단일 프로젝트를 넘어, 오늘날의 접지되지 않은 LLM에서 진정으로 접지된 GWM으로 나아가는 장기적인 AI 개발 경로를 시사합니다.

## **3\. XKG 파이프라인 해부: 이미지에서 강화된 그래프까지**

이 섹션에서는 폴라니 시스템이 이미지나 텍스트 입력으로부터 어떻게 다층적인 의미를 가진 확장된 지식 그래프(XKG)를 생성하는지, 그 기술적 과정을 단계별로 상세히 분석합니다. 이 파이프라인은 여러 최첨단 오픈소스 도구와 모델을 유기적으로 결합한 모듈식 구조를 특징으로 합니다.

### **3.1 단계별 프로세스 분석**

XKG 생성 파이프라인은 크게 세 단계로 구성됩니다: 초기 설명 생성, 기본 그래프 생성, 그리고 휴리스틱 기반 강화.

#### **3.1.1 1단계: 초기 설명 생성 (MLLM)**

프로세스는 입력 이미지로부터 시작됩니다. 이 이미지는 "세심하게 제작된 프롬프트(carefully crafted prompt)"와 함께 멀티모달 LLM(논문에서는 구체적으로 GPT-4o를 사용)에 전달됩니다.1 이 프롬프트는 모델이 단순히 보이는 것을 묘사하는 것을 넘어, 이미지의 "외현적, 암묵적, 상징적 내용(overt, implicit, and symbolic content)"을 종합하여 100단어 이내의 간결한 텍스트로 생성하도록 유도합니다.1 특히, 후속 단계인 AMR 파서의 성능을 최적화하기 위해, "연속적이고 흐르는 듯한 문장 구조(continuous, flowing sentence structure)"를 사용하도록 스타일 제약이 가해집니다.1 이 첫 단계의 품질은 전체 파이프라인의 성공에 결정적인 영향을 미칩니다. 잘 설계된 프롬프트는 모델이 처음부터 다층적인 사고를 하도록 유도하여, 후속 지식 추출을 위한 풍부한 의미론적 기반을 마련합니다.

#### **3.1.2 2단계: 기본 그래프 생성 (Text2AMR2FRED)**

1단계에서 생성된 자연어 설명은 'Text2AMR2FRED(TAF)'라는 복합적인 하위 파이프라인으로 전달되어, 정형화되고 논리적으로 타당한 지식 그래프로 변환됩니다. 이 과정은 여러 "기성(off-the-shelf)" 도구들의 연쇄적인 작업으로 이루어집니다.1

1. **텍스트 → AMR 그래프 변환**: 텍스트는 **SPRING** 파서를 사용하여 추상적 의미 표현(Abstract Meaning Representation, AMR) 그래프로 변환됩니다.1 AMR은 문장의 표면적인 통사 구조에서 벗어나 핵심적인 의미 관계를 그래프 형태로 표현합니다.  
2. **개체 연결 (Entity Linking)**: **BLINK** 도구를 사용하여 텍스트 내의 고유 명사(named entities)를 위키피디아 페이지와 연결합니다. 이 연결 정보는 AMR 그래프의 해당 노드에 휴리스틱하게 부착되어, 각 개체가 현실 세계의 어떤 대상을 지칭하는지를 명확히 합니다.1  
3. **AMR → OWL/RDF 변환**: AMR 그래프는 **AMR2FRED** 변환기에 의해 결정론적인 규칙에 따라 OWL-RDF 형식의 지식 그래프로 변환됩니다. 이 과정에서 **Framester** 온톨로지 허브가 핵심적인 역할을 합니다. Framester는 FrameNet, WordNet, DBpedia 등 다양한 지식 소스를 통합한 자원으로, 그래프 내 개념과 관계에 형식적인 의미(formal semantics)를 부여하는 기준이 됩니다.1  
4. **단어 의미 중의성 해소 (WSD)**: 마지막으로, **eWiSeR** 도구를 사용하여 그래프 내 일반 명사들의 의미를 명확히 합니다. 텍스트 내 단어들이 문맥에 맞는 WordNet 동의어 집합(synset)으로 연결되고, 이 정보는 owl:equivalentClass 및 rdfs:subClassOf 트리플 형태로 그래프에 추가됩니다. 이를 통해 각 개념은 WordNet의 의미 체계 및 Framester를 통해 연결된 **DOLCE**와 같은 상위 온톨로지의 유형과 연결되어 의미론적 깊이를 더합니다.1

이 복잡한 과정을 거쳐 생성된 결과물이 바로 "기본 그래프(Base Graph)"입니다. 이는 비정형 텍스트가 형식적이고, 논리적으로 일관되며, 의미론적으로 접지된 기호적 지식으로 변환된 첫 번째 핵심 산출물입니다.

#### **3.1.3 3단계: 휴리스틱 기반 강화 (LLM)**

기본 그래프는 Turtle 구문으로 직렬화된 후, 다시 LLM(논문에서는 Claude 3.5 Sonnet을 사용)에 "재주입(re-inject)"됩니다.1 이 단계에서는 11가지의 각기 다른 휴리스틱을 위해 특별히 설계된 프롬프트가 사용됩니다. 각 프롬프트는 LLM이 기본 그래프에 포함된 명시적 지식을 기반으로, 특정 유형의 암묵적 지식(예: 전제, 인과 관계, 도덕적 가치 등)을 추론하여

*새로운* 트리플을 생성하도록 유도합니다.1 저자들은 여러 모델을 테스트한 결과, 이러한 지식 강화 목적에 Claude 3.5 Sonnet이 가장 뛰어난 성능을 보였다고 밝혔습니다.1 이 단계는 시스템의 "신경망(Neuro)"적 강화 부분으로, 구조화된 기호적 맥락(기본 그래프)과 특정 의미 차원을 활성화하는 '소리굽쇠'(휴리스틱 프롬프트)를 결합하여 LLM의 잠재된 상식 지식을 효과적으로 이끌어냅니다.

### **표 1: XKG 생성 툴킷**

| 파이프라인 단계 | 사용된 도구/모델 | 핵심 기능 |
| :---- | :---- | :---- |
| **이미지 설명** | GPT-4o | 이미지로부터 외현적, 암묵적, 상징적 내용을 포함하는 다층적 텍스트 생성 |
| **AMR 파싱** | SPRING | 자연어 텍스트를 문법 구조에서 벗어난 의미 중심의 AMR 그래프로 변환 |
| **개체 연결** | BLINK | 텍스트 내 고유 명사를 위키데이터 개체와 연결하여 의미를 명확화 |
| **KG 변환** | AMR2FRED | AMR 그래프를 Framester 온톨로지 허브를 참조하여 형식적인 OWL/RDF 지식 그래프로 변환 |
| **단어 의미 중의성 해소** | eWiSeR | 일반 명사의 문맥적 의미를 WordNet 동의어 집합에 연결하여 명확화 |
| **KG 강화** | Claude 3.5 Sonnet | 11가지 휴리스틱 기반 프롬프트를 사용하여 기본 그래프에 암묵적 지식 트리플을 추가 |

## **4\. 암묵적 지식의 11가지 차원: 휴리스틱 기반 탐색**

폴라니 프레임워크의 핵심은 인간의 암묵적 지식을 11개의 구체적인 차원으로 나누고, 각 차원을 추출하기 위한 전용 휴리스틱을 사용한다는 점입니다. 이 휴리스틱들은 LLM의 잠재 공간을 탐색하는 '소리굽쇠' 역할을 하며, 단순한 정보의 나열을 넘어 인간 사고의 다층적인 구조를 모델링하려는 시도입니다. 이 섹션에서는 11가지 휴리스틱 각각을 정의하고, 그 인지적 중요성을 설명하며, 논문의 올림픽 우승자 사례 연구 1를 통해 구체적인 예시를 제시합니다.

이 휴리스틱들은 무작위적인 목록이 아니라, 일종의 '인지 스택(cognitive stack)'을 형성하는 것으로 이해할 수 있습니다. 이 스택은 언어의 기반에서부터 신체적 경험, 사회적 규범, 그리고 미래 예측에 이르는 인간 인지의 계층적 구조를 반영합니다.

* **언어/화용론적 계층 (Linguistic/Pragmatic Layer)**: 대화와 텍스트의 표면 아래에 있는 의미를 다룹니다.  
* **체화/인지적 계층 (Embodied/Cognitive Layer)**: 세계에 대한 우리의 신체적, 감각적 경험에서 비롯된 지식을 다룹니다.  
* **사회/문화적 계층 (Socio-Cultural Layer)**: 공유된 가치와 상징 체계에 기반한 의미를 다룹니다.  
* **인과/시간적 계층 (Causal/Temporal Layer)**: 사건의 순서, 원인과 결과, 그리고 미래에 대한 예측을 다룹니다.

### **4.1 전제 (Presuppositions)**

* **정의**: 어떤 진술이 의미를 갖기 위해 반드시 참이어야 하는 암묵적인 가정입니다.1  
* **인지적 중요성**: 공유된 배경지식에 의존하여 효율적인 의사소통을 가능하게 합니다. 모든 것을 명시적으로 말할 필요 없이 대화의 맥락을 구축합니다.  
* **사례**: "운동선수가 금메달을 땄다"는 진술은 "경기가 있었다"는 사실을 전제합니다. XKG는 ex:win\_1 (우승 사건)이 ex:presupposes ex:competition\_1 (경기 사건)과 같은 트리플로 이를 형식화할 수 있습니다.

### **4.2 대화 함의 (Conversational Implicatures)**

* **정의**: 발화의 문자적 의미를 넘어 대화의 맥락으로부터 발생하는 암시된 의미입니다. 그라이스(Grice)의 화용론에 기반합니다.1  
* **인지적 중요성**: 화자가 명시적으로 말한 것 이상의 정보를 전달할 수 있게 하여, 의사소통을 풍부하고 효율적으로 만듭니다.  
* **사례**: "근처에 주유소 있나요?"라는 질문에 "모퉁이를 돌면 하나 있어요"라고 답했다면, 그 주유소가 '영업 중일 것'이라는 함의가 있습니다. XKG는 ex:gas\_station\_1이 ex:isImpliedToBe ex:Operational과 같은 속성을 가짐을 표현할 수 있습니다.

### **4.3 사실적 영향 (Factual Impact)**

* **정의**: 사건이 참여자에게 미치는 물리적, 사회적, 인지적 결과. 예상되는 감정, 감각, 정신 상태의 변화를 포함합니다.1  
* **인지적 중요성**: 사건의 전체적인 파급 효과를 이해하고, 등장인물의 내적 상태를 추론하여 이야기에 대한 공감적 이해를 가능하게 합니다.  
* **사례**: "경기에서 우승"한 선수는 '기쁨(joy)', '자부심(pride)'과 같은 감정을 느끼고, '아드레날린 분출'과 같은 신체적 감각을 경험할 것입니다. XKG는 ex:athlete\_1이 impact:hasExpectedEmotion impact:Joy와 같은 트리플을 통해 이를 나타냅니다.1

### **4.4 이미지 스키마 (Image Schemas)**

* **정의**: 인간이 세계에 대한 경험을 조직하고 해석하는 데 도움을 주는 기본적인 인지 구조. '용기(container)', '경로(path)', '균형(balance)' 등이 포함됩니다.1  
* **인지적 중요성**: 공간적 추론과 추상적 개념 이해의 기반이 됩니다. "경기*에* 참가하다(in the competition)"나 "상자 *밖에서* 생각하다(out of the box)"와 같은 은유적 표현을 이해하는 데 필수적입니다.  
* **사례**: 올림픽 경기 장면은 '용기(Container)' 스키마(경기장), '경로(Path)' 스키마(트랙), '힘(Force)' 스키마(선수들의 경쟁) 등 다양한 이미지 스키마를 활성화합니다. XKG는 ex:competition\_1이 is:instanceOf is:ContainerSchema와 같이 표현할 수 있습니다.

### **4.5 환유적 강제 (Metonymic Coercion)**

* **정의**: 단어의 일반적인 의미가 문맥 속에서 관련된 특정 의미로 강제적으로 해석되는 언어 현상입니다.1  
* **인지적 중요성**: 더 효율적이고 미묘한 의사소통을 가능하게 합니다. 부분으로 전체를 나타내는 등 간결한 표현을 허용합니다.  
* **사례**: "백악관이 새로운 정책을 발표했다"는 문장에서 '백악관'은 물리적 건물이 아니라 '미국 정부'라는 의미로 강제됩니다. XKG는 ex:WhiteHouse가 meta:represents ex:US\_Government와 같이 표현할 수 있습니다.

### **4.6 도덕적 가치 기반 강제 (Moral Value-driven Coercion)**

* **정의**: 행동이나 진술의 문자적 의미가 도덕적 또는 사회적으로 부과된 해석으로 강제되는 현상입니다.1  
* **인지적 중요성**: 인간의 행동과 의사결정을 안내하는 기저의 가치 체계를 반영합니다. 단순한 사실 기술을 넘어 도덕적 판단과 평가를 가능하게 합니다.  
* **사례**: "그녀는 항상 약속을 지킨다"는 말은 행동에 대한 묘사를 넘어, 그 사람의 '성실함'과 '신뢰성'에 대한 도덕적 판단으로 해석될 수 있습니다. 우승한 선수의 행동은 '헌신(dedication)', '노력(hard work)'과 같은 가치를 구현한 것으로 해석될 수 있습니다.

### **4.7 상징적 강제 (Symbolic Coercion)**

* **정의**: 문자적 의미가 상징적 해석으로 변환되는 과정입니다. 퍼스(Peirce)의 기호학에 뿌리를 둡니다.1  
* **인지적 중요성**: 복잡한 아이디어를 친숙한 개념, 대상, 이미지에 고정시켜 소통을 용이하게 합니다. 문화적, 국가적 정체성을 표현하는 데 자주 사용됩니다.  
* **사례**: 스포츠 경기에서 "캥거루 군단이 경기에서 이겼다"는 말은 유대류 동물이 아닌 '호주 국가대표팀'을 상징적으로 나타냅니다. 사례 연구의 선수 유니폼에 있는 국기는 '국가적 자부심(national pride)'을 상징합니다.

### **4.8 사건 순서 (Event Sequences)**

* **정의**: 텍스트에 언급된 사건들 사이의 시간적 선후 관계를 포착합니다.1  
* **인지적 중요성**: 인과 관계, 이야기의 진행, 행동의 논리적 흐름을 이해하는 데 필수적인 시간적 추론을 가능하게 합니다.  
* **사례**: "비행 후, 선수들은 경기까지 이틀의 시간이 있다"는 문장에서 시스템은 '비행 → 이틀 → 경기'라는 순서를 인식합니다. 사례 연구에서는 '경기(race) → 우승(win) → 축하(celebrate)'의 순서가 추론될 수 있습니다.

### **4.9 인과 관계 (Causal Relations)**

* **정의**: 텍스트에 언급된 사건이나 상태 간의 원인-결과 관계를 포착합니다.1  
* **인지적 중요성**: 동기를 이해하고, 결과를 예측하며, 상황에 대한 일관된 정신 모델을 구축하는 데 근본적인 역할을 합니다.  
* **사례**: "폭우로 인해 경기가 연기되었다"는 문장에서 '폭우'가 '경기 연기'의 원인임을 인식합니다. 사례 연구에서는 '수년간의 훈련(years of training)'이 '우승(victory)'의 원인으로 추론될 수 있습니다.

### **4.10 암시된 미래 사건 (Implied Future Events)**

* **정의**: 주어진 정보를 바탕으로 발생 가능성이 높은 결과나 후속 사건을 추론하는 것입니다.1  
* **인지적 중요성**: 현재 상황을 바탕으로 미래 시나리오를 예측하고 대비하는 인간의 능력을 반영합니다. 장기적인 계획과 의사결정에 중요합니다.  
* **사례**: 금메달을 딴 선수는 앞으로 '인터뷰 요청', '광고 계약', '국가적 환영 행사' 등의 미래 사건을 겪을 가능성이 높습니다. XKG는 ex:victory\_1이 ex:impliesFutureEvent ex:SponsorshipDeals와 같이 표현할 수 있습니다.

### **4.11 암시된 잠재적 비사건 (Implied Potential Non-events)**

* **정의**: 다른 상황이나 결정으로 인해 일어나지 않게 된, 일어날 수도 있었던 사건입니다.1  
* **인지적 중요성**: 대안적 시나리오에 대한 이해, 즉 반사실적 추론(counterfactual reasoning)을 가능하게 합니다. 이는 결정의 중요성과 이야기의 더 넓은 함의를 이해하는 데 필수적입니다.  
* **사례**: "그녀는 경기에 참가하지 않기로 결정했다"는 문장은 '경기에 참가하는' 비사건을 암시합니다. 우승한 선수의 경우, '경기에서 지는 것' 또는 '부상으로 불참하는 것'이 잠재적 비사건이 될 수 있습니다.

## **5\. 실험적 심층 분석: XKG 프레임워크 검증**

이론적 제안의 타당성을 입증하기 위해, 논문은 세 가지의 체계적인 실험을 수행합니다. 이 실험들은 XKG 생성 파이프라인의 성능을 다각도에서 평가하고, 그 결과가 실제 세계의 지식 표현 및 추론 작업에 어떤 의미를 갖는지 보여줍니다. 이 섹션에서는 각 실험의 설계, 핵심 결과, 그리고 그로부터 도출되는 심층적인 함의를 분석합니다.

### **5.1 실험 1: 올림픽 우승 사례 연구**

첫 번째 실험은 2024년 파리 올림픽 여자 100m 결승전에서 우승한 세인트루시아의 줄리엔 알프레드(Julien Alfred) 선수의 이미지 1를 사용하여 전체 파이프라인의 작동 과정을 상세히 보여주고 그 결과물을 평가합니다. 이 이미지는 사용된 모델들의 학습 데이터 컷오프 시점 이후에 촬영된 것으로, 모델이 사전에 이미지를 학습했을 가능성을 배제하기 위해 신중하게 선택되었습니다.

* **기본 그래프 분석**: 이미지로부터 생성된 텍스트 설명을 Text2AMR2FRED 파이프라인에 입력하여 생성된 초기 '기본 그래프'는 293개의 OWL 액시엄(axiom)으로 구성되었습니다. 이 그래프는 WordNet 엔티티 33개, PropBank 역할 23개 및 프레임 20개, 그리고 DOLCE 상위 온톨로지 자원 10개와 정렬되어, 초기 기호적 표현이 매우 풍부하고 의미론적으로 접지되어 있음을 보여줍니다.1  
* **XKG 분석**: 11개의 휴리스틱을 적용하여 생성된 확장된 지식 그래프(XKG)들은 그 크기와 복잡성에서 상당한 차이를 보였습니다. '이미지 스키마' 그래프는 63개의 액시엄으로 가장 컸고, '도덕적 가치 기반 강제' 그래프는 12개로 가장 작았습니다.1 이러한 차이는 각 휴리스틱이 특정 맥락(스포츠 장면)에서 활성화되는 정도가 다름을 시사하는 중요한 발견입니다.  
* **검증 결과 분석**:  
  * **논리적 무결성**: 생성된 모든 XKG는 **HermiT 추론기**를 사용하여 논리적 일관성을 검증받았습니다. 그 결과, '환유적 강제' 그래프에서 단 하나의 비일관성이 발견되었습니다. 이는 특정 개체(athlete\_1)가 '객체(Object)'이면서 동시에 '사건(Event)'으로 잘못 분류된 경우였습니다.1  
  * **인간 평가 타당성**: 5명의 인간 평가자가 생성된 트리플들의 타당성을 5점 리커트 척도로 평가했습니다. 대부분의 휴리스틱은 평균 3점("어느 정도 타당함") 이상을 기록했습니다. 특히 '사실적 영향'과 '대화 함의'는 4.29점 이상의 높은 점수를 받았으나, '암시된 미래 사건'과 '잠재적 비사건'은 상대적으로 낮은 점수를 받았습니다.1

이 실험 결과에서 주목할 점은 시스템의 성공뿐만 아니라 실패 또한 유익한 정보를 제공한다는 것입니다. '환유적 강제' 그래프에서 발견된 논리적 비일관성은 LLM의 창의성이 때로 논리적 오류를 범할 수 있음을 보여주지만, 동시에 기호적 추론기(HermiT)가 이러한 오류를 탐지하는 '논리적 안전장치(logical backstop)' 역할을 효과적으로 수행함을 입증합니다. 또한, 불확실성이 높은 개념(미래 사건)이나 추상성이 강한 개념(이미지 스키마)에 대해 인간 평가 점수가 낮게 나온 것은, 시스템의 성능 저하가 인간의 인지적 한계와 유사한 패턴을 보인다는 점에서 흥미롭습니다. 이는 완벽한 시스템을 추구하는 대신, (a) 잘 정의된 맥락에 대해 매우 타당한 지식을 생성하고, (b) 모호하거나 비일관적인 상황에 직면했을 때 예측 가능하고 탐지 가능한 방식으로 실패하는 '우아한 실패(graceful failure)'를 보이는 시스템의 가치를 부각합니다.

### **표 2: XKG 휴리스틱에 대한 인간 평가 요약**

| 휴리스틱 | 평균 타당성 점수 (μ) | 표준 편차 (σ) | 핵심 해석 |
| :---- | :---- | :---- | :---- |
| **사실적 영향** | 4.32 | 1.18 | 평가자 간 높은 동의도, 구체적이고 공감 가능한 개념 |
| **대화 함의** | 4.31 | 1.60 | 높은 타당성을 보이나, 평가자 간 해석 차이로 편차가 큼 |
| **도덕적 가치 기반 강제** | 4.29 | 0.47 | 매우 높은 동의도(낮은 편차), 명확한 사회적 가치 반영 |
| **전제** | 4.18 | 1.05 | 배경지식 추론의 타당성이 높게 평가됨 |
| **상징적 강제** | 3.80 | 0.86 | 비교적 명확한 상징 해석으로 안정적인 점수 획득 |
| **인과 관계** | 3.72 | 1.08 | 원인-결과 추론의 타당성은 인정되나, 복잡성으로 편차 존재 |
| **사건 순서** | 3.70 | 0.92 | 시간적 순서 추론은 비교적 일관된 평가를 받음 |
| **이미지 스키마** | 3.64 | 1.20 | 추상적인 개념으로 인해 평가자 간 이해도 및 점수 편차가 큼 |
| **환유적 강제** | 3.61 | 1.20 | 언어적 미묘함으로 인해 해석의 차이가 발생 |
| **잠재적 비사건** | 3.61 | 0.98 | 반사실적 추론의 어려움으로 인해 중간 수준의 점수 획득 |
| **암시된 미래 사건** | 2.94 | 1.57 | 가장 낮은 점수와 가장 높은 편차, 미래의 불확실성을 반영 |

### **5.2 실험 2: 모델들의 전쟁**

두 번째 실험은 세 가지 다른 LLM(Claude 3.5 Sonnet, GPT-4o, Mistral Large 2)을 사용하여 지식 강화의 일관성과 신뢰성을 비교 분석합니다. 이 실험의 독특한 점은 이 모델들을 트리플을 *생성*하는 역할뿐만 아니라, 생성된 트리플의 타당성을 평가하는 *합성 평가자(synthetic annotators)* 역할로도 활용했다는 것입니다.1

* **핵심 발견**:  
  * **생산성**: 모델들은 휴리스틱에 따라 매우 다른 양의 트리플을 생성했습니다. 특히 Mistral은 '전제' 휴리스틱에서 100개가 넘는 트리플을 생성하는 '과잉 생산자'의 면모를 보인 반면, 다른 모델들은 더 보수적이었습니다.1  
  * **자기 일관성**: Claude와 Mistral은 자신이 생성한 결과물에 대해 매우 높은 점수를 부여하며 높은 자기 일관성(self-coherence \> 0.8)을 보였습니다. 반면, GPT-4o는 상당히 낮은 자기 일관성(0.35-0.75)을 나타냈습니다.1  
  * **모델 간 동의도**: 가장 충격적인 결과는 모델 간 동의도가 전반적으로 매우 낮았다는 점입니다 (크리펜도르프 알파 대부분 \< 0.2, 코헨의 카파 \< 0.4).1

이 결과는 "상식의 다원성(Plurality of Commonsense)"이라는 심오한 문제를 제기합니다. 모델들은 생성된 트리플이 전반적으로 '그럴듯하다'는 데에는 동의하지만(높은 평균 점수), *어떤* 특정 트리플이 그럴듯한지에 대해서는 서로 강력하게 *불일치*합니다. 이는 각 LLM이 훈련 데이터를 통해 자신만의 GWM, 즉 자신만의 '상식 버전'을 학습했음을 시사합니다. 이 상식 버전들은 각각 내부적으로는 일관되지만(Claude/Mistral의 높은 자기 일관성), 서로 간에는 상당한 차이를 보입니다.

이 발견은 AI 분야에 중대한 함의를 던집니다. 우리는 단일하고 객관적인 AI 추론기로 수렴하고 있는 것이 아니라, 오히려 다원적인 '기계 마음(machine minds)'을 구축하고 있을 수 있습니다. 뉴로심볼릭 시스템 개발자에게 이는 LLM을 선택하는 것이 단순한 기술적 결정이 아니라, 어떤 '세계관' 또는 '추론 스타일'을 시스템에 내장할 것인지를 결정하는 철학적 선택이 됨을 의미합니다. 이는 AI의 안전성, 신뢰성, 예측 가능성에 대한 논의를 근본적으로 바꾸어 놓을 수 있습니다.

### **표 3: XKG 파이프라인 내 LLM 비교 분석**

| 구분 | Claude 3.5 Sonnet | GPT-4o | Mistral Large 2 |
| :---- | :---- | :---- | :---- |
| **생산성 프로필** | 일관적이고 안정적인 생성량 | 낮고 가변적인 생성량 | '전제'에서 과잉 생산, 전반적으로 가변적 |
| **자기 일관성 점수 (평균)** | 높음 (\>0.8) | 낮음 (\<0.75) | 높음 (\>0.8) |
| **모델 간 동의도 프로필** | GPT-4o와 가장 높은 동의도 보임 | Claude와 비교적 높은 동의도, Mistral과 낮음 | 다른 두 모델과 자주 불일치하며 가장 낮은 동의도 |

### **5.3 실험 3: 다운스트림 응용 \- 미래 사건 예측**

세 번째 실험은 시스템의 실용성을 검증하기 위해, 12개의 최신 뉴욕 타임스 기사로부터 미래에 일어날 법한 사건을 예측하는 다운스트림 작업을 수행했습니다.1

* **방법론**: 각 기사에 대해 '암시된 미래 사건' XKG를 생성했습니다. 이 구조화된 출력은 여러 LLM이 생성한 순수 텍스트 예측과 비교되었습니다. XKG의 출력이 얼마나 더 미묘하고 복잡한지를 측정하기 위해 "구조 증식 계수(Structure Multiplication Factor, SMF)"라는 새로운 지표가 도입되었습니다.  
* **결과**: XKG 접근법은 LLM의 유효한 예측을 모두 포착하여 100%의 정밀도를 보였으며, 여기에 더해 상당한 양의 새로운 구조화된 정보를 추가하여 평균 2.74의 SMF를 달성했습니다. 한 예시에서는 LLM이 생성한 6개의 예측을 15개의 구조화된 트리플로 확장하여 2.5의 SMF를 기록했습니다.1

이 실험은 "구조는 의미의 증식기(Structure is a Meaning Multiplier)"라는 중요한 원리를 보여줍니다. "법적 분쟁"과 같은 LLM의 비정형 텍스트 예측은 단일한 문자열에 불과합니다. 하지만 XKG는 이를 특정 행위자(예: 시민 단체), 잠재적 원인(예: 새로운 정책), 그리고 그래프 내 다른 관련 개념들과 연결된 형식적인 사건으로 표현할 수 있습니다. 즉, OWL/RDF와 같은 기호적 구조는 LLM으로부터 얻은 원시적인 의미론적 내용을 가져와 형식적이고, 컴퓨터로 처리 가능하며, 추론이 가능한 프레임워크 안에 배치함으로써 그 유용성을 배가시킵니다. SMF는 "LLM이 있는데 왜 굳이 KG를 써야 하는가?"라는 근본적인 질문에 대한 구체적이고 정량적인 답변을 제공하며, 뉴로심볼릭 시스템의 실질적인 가치를 명확히 보여줍니다.

## **6\. 통찰과 함의: 접지된 AI의 미래**

본 보고서에서 심층 분석한 연구는 단순히 새로운 기술을 제시하는 것을 넘어, AI가 인간과 같은 이해에 도달하기 위한 경로에 대한 중요한 통찰과 방향성을 제공합니다. 이 마지막 섹션에서는 연구의 핵심적인 기여를 요약하고, 앞으로의 도전 과제를 조망하며, 이 연구가 AI의 미래에 미칠 광범위한 영향을 고찰합니다.

### **6.1 핵심 요약**

이 연구의 기여는 세 가지 핵심적인 발견으로 요약될 수 있습니다.

1. **효과적인 암묵적 지식 추출 파이프라인**: 이 연구는 11가지 유형의 암묵적 지식을 추출하여 지식 그래프를 강화하는, 모듈식이고 복제 가능한 새로운 뉴로심볼릭 파이프라인을 성공적으로 시연했습니다.1 실험 결과, 생성된 지식은 인간에게 대체로 타당하게 받아들여지고 논리적으로도 건전하여, LLM이 상식 추론을 위한 '잠재적 반응자'로 효과적으로 사용될 수 있음을 입증했습니다.1  
2. **상식의 다원성 발견**: 서로 다른 LLM들이 타당성 판단에서 매우 낮은 상호 동의도를 보인다는 발견은, 이 모델들이 각기 다른 '상식의 버전'을 학습했음을 시사합니다.1 이는 신뢰할 수 있는 AI 시스템을 구축하는 데 있어 우리가 단일한 정답이 아닌, 다원적인 '기계 마음'을 다루어야 한다는 근본적인 과제를 제기합니다.  
3. **구조화된 지식의 가치 정량화**: '구조 증식 계수(SMF)'라는 새로운 지표를 통해, XKG 파이프라인의 구조화된 출력이 단순한 LLM의 텍스트 출력보다 다운스트림 작업에서 실질적으로 더 가치 있음을 정량적으로 증명했습니다.1 이는 뉴로심볼릭 접근법의 실용적 우수성을 뒷받침하는 강력한 증거입니다.

### **6.2 도전 과제 해결: 향후 연구 방향**

논문은 현재 시스템의 한계를 인식하고, 이를 개선하기 위한 명확한 미래 연구 로드맵을 제시합니다.1

* **프롬프트 정교화**: 현재의 표준 템플릿을 넘어, 각 휴리스틱의 특성에 더 잘 맞는 맞춤형 프롬프트를 개발하여 결과의 질을 높이는 연구가 필요합니다.  
* **속성 전문화**: dul:associatedWith와 같은 일반적인 속성 대신, DOLCE Zero와 같은 상위 온톨로지와 정렬된 더 구체적이고 전문화된 속성을 사용하여 추론 능력을 강화해야 합니다.  
* **주제화(Topicalization)**: 생성된 트리플을 입력 이미지의 특정 영역과 연결하여, "이미지의 어느 부분이 이 지식과 관련 있는가?"라는 질문에 답할 수 있도록 시스템을 확장해야 합니다.  
* **모델 접근성 확대**: 현재는 고가의 상용 API에 의존하지만, Phi 3.5와 같은 더 작고 효율적인 오픈소스 모델에서도 효과적으로 작동하도록 프로세스를 개선하여 기술의 접근성을 높여야 합니다.  
* **사용자 정의 휴리스틱**: 사용자가 자신만의 프롬프트를 정의하여 특정 도메인에 맞는 맞춤형 지식을 추출할 수 있도록 시스템을 개방하는 것은 이 기술의 활용 범위를 폭발적으로 증가시킬 것입니다.

이러한 계획들은 연구 프로토타입을 견고하고 범용적인 플랫폼으로 발전시키기 위한 구체적인 청사진을 보여줍니다.

### **6.3 광범위한 영향: 인간과 같은 추론을 향한 길**

결론적으로, 이 연구는 새로운 도구 이상의 것을 제공합니다. 그것은 AI 연구에 새로운 관점을 제시합니다. 암묵적이고, 상식적이며, 접지된 지식의 추출에 초점을 맞춤으로써, 이 연구는 인간의 추론을 유연하고 강건하게 만드는 바로 그 핵심 요소를 다룹니다. '폴라니' 시스템은 AI의 오랜 난제인 프레임 문제를 해결하고 진정한 접지된 세계 모델(GWMs)을 구축하기 위한 구체적인 발걸음입니다.

논문의 저자들이 결론에서 언급했듯이, 이 연구는 "인간과 같은 추론 및 맥락적 이해가 가능한 시스템"의 개발에 기여합니다.1 그 여정은 아직 멀지만, 이 연구는 유망한 지도와 강력한 도구 세트, 그리고 결정적인 통찰을 제공합니다. 그중 가장 중요한 통찰은 아마도 앞으로 나아갈 길이 단 하나의 기계적 상식이 아니라, 다수의 서로 다른 기계 학습된 상식들 사이를 항해하는 과정이 될 것이라는 깨달음일 것입니다.

#### **참고 자료**

1. Neurosymbolic\_graph\_enrichment\_for\_Grounded\_World\_Models.pdf  
2. Neurosymbolic graph enrichment for Grounded World Models, 6월 26, 2025에 액세스, [https://cris.unibo.it/bitstream/11585/1011013/1/1-s2.0-S030645732500069X-main.pdf](https://cris.unibo.it/bitstream/11585/1011013/1/1-s2.0-S030645732500069X-main.pdf)
